{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "sXg_imxXPeKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
        "\n",
        "# Initialize the accelerator\n",
        "accelerator = Accelerator()\n",
        "\n",
        "# read data\n",
        "train_raw = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\n",
        "test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "qJc8gKhSPeKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package Importing"
      ],
      "metadata": {
        "id": "oBmcaeryPeKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig, RobertaTokenizer, RobertaModel\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Sampler, Dataset, DataLoader\n",
        "from accelerate import Accelerator\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import copy\n",
        "import os\n",
        "import multiprocessing\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import string\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from collections import OrderedDict"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "PLXeqru6PeKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Preprocessing"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-07T02:32:57.557413Z",
          "iopub.execute_input": "2023-07-07T02:32:57.557874Z",
          "iopub.status.idle": "2023-07-07T02:32:57.566346Z",
          "shell.execute_reply.started": "2023-07-07T02:32:57.557838Z",
          "shell.execute_reply": "2023-07-07T02:32:57.565460Z"
        },
        "id": "FMCiMn5IPeKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove duplicates\n",
        "train_no_duplicates = train_raw.drop_duplicates('text')\n",
        "# remove contradictory\n",
        "duplicates_df = train_raw[train_raw.text.duplicated(keep=False)].sort_values('text')\n",
        "contradictory_tweets = set()\n",
        "for tweet in list(duplicates_df.text):\n",
        "    if len(set(duplicates_df[duplicates_df['text'] == tweet].target)) > 1:\n",
        "        contradictory_tweets.add(tweet)\n",
        "\n",
        "contradictory_tweets = list(contradictory_tweets)\n",
        "\n",
        "filtered_df = train_no_duplicates[~train_no_duplicates['text'].isin(contradictory_tweets)]\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
        "    # Remove user @ references and '#' from text\n",
        "    text = re.sub(r'\\@\\w+|\\#','', text)\n",
        "    # Remove punctuations\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Convert to lowercase to maintain consistency\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Apply the text cleaning function\n",
        "filtered_df['clean_text'] = filtered_df['text'].apply(clean_text)\n",
        "test['clean_text'] = test['text'].apply(clean_text)\n",
        "\n",
        "def combine_columns(row):\n",
        "    values = [f\"{col}: {str(row[col])}\" for col in row.index[1:-2] if pd.notnull(row[col])]\n",
        "    return ' '.join(values)\n",
        "\n",
        "# Combine the three columns into a single column\n",
        "filtered_df['combined'] = filtered_df.apply(combine_columns, axis=1)\n",
        "filtered_df['final_text'] =  filtered_df['clean_text']+' '+ filtered_df['combined']\n",
        "\n",
        "#test set\n",
        "filtered_test = test.copy()\n",
        "filtered_test['combined'] = filtered_test.apply(combine_columns, axis=1)\n",
        "filtered_test['final_text'] =  filtered_test['clean_text']+' '+ filtered_test['combined']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-22T21:44:54.648331Z",
          "iopub.execute_input": "2023-05-22T21:44:54.648762Z",
          "iopub.status.idle": "2023-05-22T21:45:09.011742Z",
          "shell.execute_reply.started": "2023-05-22T21:44:54.648731Z",
          "shell.execute_reply": "2023-05-22T21:45:09.009856Z"
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "collapsed": true,
        "trusted": true,
        "id": "7At95SowPeKD",
        "outputId": "5177f917-d933-42e7-d7cd-b40ebf7a134f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "18\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_32/2659865553.py:74: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  filtered_df['clean_text'] = filtered_df['text'].apply(clean_text)\n/tmp/ipykernel_32/2659865553.py:82: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  filtered_df['combined'] = filtered_df.apply(combine_columns, axis=1)\n/tmp/ipykernel_32/2659865553.py:83: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  filtered_df['final_text'] =  filtered_df['clean_text']+' '+ filtered_df['combined']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Model"
      ],
      "metadata": {
        "id": "-1c4X3P5PeKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, dataframe, text_column, tokenizer, target='target', max_length = 256):\n",
        "        self.data = []\n",
        "\n",
        "        for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), ncols=70):\n",
        "            text = row[text_column]\n",
        "            tokenized = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors='pt')\n",
        "            self.data.append(((tokenized['input_ids'][0].to(device), tokenized['attention_mask'][0].to(device)), torch.tensor(row[target]).to(device)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def train_valid_split(self, train_fraction=.8, shuffle=True):\n",
        "        num_train_examples = int(len(self) * train_fraction)\n",
        "        train_dataset = copy.deepcopy(self)\n",
        "\n",
        "        if shuffle:\n",
        "            random.shuffle(train_dataset.data)\n",
        "\n",
        "        valid_dataset = copy.deepcopy(train_dataset)\n",
        "        train_dataset.data = train_dataset.data[:num_train_examples]\n",
        "        valid_dataset.data = valid_dataset.data[num_train_examples:]\n",
        "\n",
        "        return train_dataset, valid_dataset"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "X0isFhl0PeKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDatasetTest(Dataset):\n",
        "    def __init__(self, dataframe, text_column, tokenizer, max_length = 256):\n",
        "        self.data = []\n",
        "\n",
        "        for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), ncols=70):\n",
        "            text = row[text_column]\n",
        "            tokenized = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors='pt')\n",
        "            self.data.append((torch.tensor(row['id']).to(device) ,(tokenized['input_ids'][0].to(device), tokenized['attention_mask'][0].to(device))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "UDAe398yPeKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FinetuneClassifier(nn.Module):\n",
        "    def __init__(self, model=model_checkpoint, classes=2, head_dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = AutoModel.from_pretrained(model)\n",
        "        hidden_size = self.model.config.hidden_size\n",
        "\n",
        "        self.project = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(head_dropout),\n",
        "            torch.nn.Linear(hidden_size, hidden_size),\n",
        "            torch.nn.Dropout(head_dropout),\n",
        "            torch.nn.Linear(hidden_size, classes) # projection\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        res = self.model.forward(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "        res = res[0]\n",
        "        res = res[:,0,:] # encoding for <s> token\n",
        "        res = self.project(res)\n",
        "        return res\n",
        "\n",
        "    def parameters_num(self):\n",
        "        return sum(p.numel() for p in self.parameters())"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "zh_yO76iPeKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,\n",
        "          train_dataloader,\n",
        "          valid_dataloader,\n",
        "          steps,\n",
        "          optimizer,\n",
        "          accelerator,\n",
        "          blind_steps=None,\n",
        "          loss_fn=torch.nn.BCELoss(),\n",
        "          main_metric=('f1', f1_score),\n",
        "          additional_metrics=[],\n",
        "          filepath='model_best_BERT.pt',\n",
        "          load_best=True,\n",
        "          scheduler=None,\n",
        "          losses_dict=None):\n",
        "\n",
        "    if blind_steps == None:\n",
        "        blind_steps = len(train_dataloader) // 4\n",
        "\n",
        "    def evaluate():  # the first score returned is the main\n",
        "        model.eval()\n",
        "\n",
        "        y_trues = []\n",
        "        y_hats = []\n",
        "\n",
        "        loss = 0\n",
        "        k = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in valid_dataloader:\n",
        "\n",
        "                (ids, mask), y_true = batch\n",
        "                ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "                y_true = accelerator.prepare(y_true)\n",
        "                hots = torch.nn.functional.one_hot(y_true, 2).to(dtype=torch.float)\n",
        "                y_hat = torch.softmax(model.forward(input_ids=ids, attention_mask=mask),dim=-1)\n",
        "\n",
        "                loss += float(loss_fn(y_hat, hots))\n",
        "                k += 1\n",
        "\n",
        "                for i in range(y_true.shape[0]):\n",
        "                    y_trues.append(int(y_true[i]))\n",
        "                    y_hats.append(1 if y_hat[i][0] < y_hat[i][1] else 0)\n",
        "\n",
        "        scores = [(main_metric[0], main_metric[1](y_trues, y_hats))]\n",
        "\n",
        "        for metric in additional_metrics:\n",
        "            scores.append((metric[0], metric[1](y_trues, y_hats)))\n",
        "\n",
        "        model.train()\n",
        "        return scores + [('valid_loss', loss/k)]\n",
        "\n",
        "\n",
        "    def render_scores(scores, step, best=None):\n",
        "        print('{:05d} steps'.format(step), end=' ')\n",
        "\n",
        "        for score in scores:\n",
        "            print(\"| {}: {:.3f}\".format(*score), end=' ')\n",
        "\n",
        "        if best != None:\n",
        "            print('| best_score: {:.3f}'.format(best))\n",
        "\n",
        "\n",
        "    # initial scores\n",
        "    scores = evaluate()\n",
        "    render_scores(scores, 0)\n",
        "    best_score = scores[0][1]\n",
        "    torch.save(accelerator.unwrap_model(model).state_dict(), filepath)\n",
        "\n",
        "    # logs\n",
        "    if losses_dict != None:\n",
        "        losses_dict['train_loss'] = []\n",
        "        losses_dict['valid_loss'] = []\n",
        "        losses_dict[main_metric[0]] = []\n",
        "\n",
        "    epoch_loss = 0\n",
        "    k = 0\n",
        "\n",
        "    train_iter = iter(train_dataloader)\n",
        "    model.train()\n",
        "\n",
        "    for step in tqdm(range(steps)):\n",
        "\n",
        "        # retrieving a batch\n",
        "        try:\n",
        "            batch = next(train_iter)\n",
        "        except:\n",
        "            train_iter = iter(train_dataloader)\n",
        "            batch = next(train_iter)\n",
        "\n",
        "        (ids, mask), y_true = batch\n",
        "        ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "        y_true = accelerator.prepare(y_true)\n",
        "\n",
        "        # prediction\n",
        "        y_hat = torch.softmax(model.forward(input_ids=ids, attention_mask=mask),dim=-1)\n",
        "        hots = torch.nn.functional.one_hot(y_true, 2).to(dtype=torch.float)\n",
        "        loss = loss_fn(y_hat, hots)\n",
        "\n",
        "        # backprop\n",
        "        optimizer.zero_grad()\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler != None:\n",
        "            scheduler.step()\n",
        "\n",
        "        epoch_loss += float(loss)\n",
        "        k += 1\n",
        "\n",
        "        # evaluation\n",
        "        if (step + 1) % blind_steps == 0:\n",
        "            scores = evaluate() + [('train_loss', epoch_loss/k)]\n",
        "\n",
        "            if losses_dict != None:\n",
        "                losses_dict['valid_loss'].append(float(scores[-2][1]))\n",
        "                losses_dict['train_loss'].append(float(scores[-1][1]))\n",
        "                losses_dict[main_metric[0]].append(float(scores[0][1]))\n",
        "\n",
        "            if scores[0][1] > best_score:\n",
        "                best_score = scores[0][1]\n",
        "                torch.save(accelerator.unwrap_model(model).state_dict(), filepath)\n",
        "\n",
        "            render_scores(scores, step + 1, best=best_score)\n",
        "            epoch_loss = 0\n",
        "            k = 0\n",
        "\n",
        "    if load_best:\n",
        "        state_dict = torch.load(filepath)\n",
        "\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            if \"module.\" not in k:\n",
        "                name = 'module.' + k\n",
        "                new_state_dict[name] = v\n",
        "\n",
        "        model.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "lT34gknfPeKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = accelerator.device\n",
        "model_checkpoint = \"bert-large-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Create an instance of your custom Dataset class\n",
        "dataset = MyDataset(filtered_df, 'final_text', tokenizer)\n",
        "train_dataset, valid_dataset = dataset.train_valid_split()\n",
        "\n",
        "dataset_test = MyDatasetTest(filtered_test, 'final_text', tokenizer)\n",
        "\n",
        "# Create a DataLoader\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = FinetuneClassifier(head_dropout=.1)\n",
        "model = nn.DataParallel(model)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, total_iters=500)\n",
        "logs_dict = {}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-22T21:45:42.722106Z",
          "iopub.execute_input": "2023-05-22T21:45:42.722606Z",
          "iopub.status.idle": "2023-05-22T21:50:42.360378Z",
          "shell.execute_reply.started": "2023-05-22T21:45:42.722567Z",
          "shell.execute_reply": "2023-05-22T21:50:42.359411Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "trusted": true,
        "id": "hQVw7OeZPeKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "  model,\n",
        "  train_dataloader,\n",
        "  valid_dataloader,\n",
        "  2000,\n",
        "  optimizer,\n",
        "  accelerator,\n",
        "  blind_steps=100,\n",
        "  additional_metrics=[('precision', precision_score), ('recall', recall_score),('accuracy', accuracy_score)],\n",
        "  losses_dict=logs_dict,\n",
        "  scheduler=scheduler\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-22T21:45:42.722106Z",
          "iopub.execute_input": "2023-05-22T21:45:42.722606Z",
          "iopub.status.idle": "2023-05-22T21:50:42.360378Z",
          "shell.execute_reply.started": "2023-05-22T21:45:42.722567Z",
          "shell.execute_reply": "2023-05-22T21:50:42.359411Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "trusted": true,
        "id": "7FjJ7fw9PeKF",
        "outputId": "89bdd9bd-c520-4da3-d74b-405bba75b6ff",
        "colab": {
          "referenced_widgets": [
            "86f5ece25dda482cbdea6549c021c4a3",
            "2604e961b7d840a6bf7ac676c0a0dba0",
            "c0e1537812b84d3ab111dea11d009409",
            "bd286860e4cd4b04ac17f54ea7e83194",
            "ef68a3f8ec0d4c8f9bf72d9a44426657"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86f5ece25dda482cbdea6549c021c4a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2604e961b7d840a6bf7ac676c0a0dba0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0e1537812b84d3ab111dea11d009409"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd286860e4cd4b04ac17f54ea7e83194"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "100%|████████████████████████████| 7485/7485 [00:12<00:00, 583.51it/s]\n100%|███████████████████████████| 3263/3263 [00:02<00:00, 1165.81it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef68a3f8ec0d4c8f9bf72d9a44426657"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00000 steps | f1: 0.281 | precision: 0.398 | recall: 0.217 | accuracy: 0.525 | valid_loss: 0.691 ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [03:19<00:00,  1.99s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00100 steps | f1: 0.722 | precision: 0.784 | recall: 0.669 | accuracy: 0.780 | valid_loss: 0.489 | train_loss: 0.606 | best_score: 0.722\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa Model"
      ],
      "metadata": {
        "id": "iwaDM2-VPeKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, dataframe, text_column, tokenizer, target='target', max_length = 256):\n",
        "        self.data = []\n",
        "\n",
        "        for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), ncols=70):\n",
        "            text = row[text_column]\n",
        "            tokenized = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors='pt')\n",
        "            self.data.append(((tokenized['input_ids'][0].to(device), tokenized['attention_mask'][0].to(device)), torch.tensor(row[target]).to(device)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def train_valid_split(self, train_fraction=.8, shuffle=True):\n",
        "        num_train_examples = int(len(self) * train_fraction)\n",
        "        train_dataset = copy.deepcopy(self)\n",
        "\n",
        "        if shuffle:\n",
        "            random.shuffle(train_dataset.data)\n",
        "\n",
        "        valid_dataset = copy.deepcopy(train_dataset)\n",
        "        train_dataset.data = train_dataset.data[:num_train_examples]\n",
        "        valid_dataset.data = valid_dataset.data[num_train_examples:]\n",
        "\n",
        "        return train_dataset, valid_dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-07T02:30:19.413044Z",
          "iopub.execute_input": "2023-07-07T02:30:19.413775Z",
          "iopub.status.idle": "2023-07-07T02:30:19.866301Z",
          "shell.execute_reply.started": "2023-07-07T02:30:19.413737Z",
          "shell.execute_reply": "2023-07-07T02:30:19.864646Z"
        },
        "jupyter": {
          "source_hidden": true,
          "outputs_hidden": true
        },
        "collapsed": true,
        "trusted": true,
        "id": "aHJglM_0PeKF",
        "outputId": "6b6f809c-3ac1-414f-bbf1-f690a99cc12b"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataframe, text_column, tokenizer, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m []\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'Dataset' is not defined",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDatasetTest(Dataset):\n",
        "    def __init__(self, dataframe, text_column, tokenizer, max_length = 256):\n",
        "        self.data = []\n",
        "\n",
        "        for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), ncols=70):\n",
        "            text = row[text_column]\n",
        "            tokenized = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors='pt')\n",
        "            self.data.append((torch.tensor(row['id']).to(device) ,(tokenized['input_ids'][0].to(device), tokenized['attention_mask'][0].to(device))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "oBDIlVT1PeKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FinetuneClassifier(nn.Module):\n",
        "    def __init__(self, model=model_checkpoint, classes=2, head_dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = RobertaModel.from_pretrained(model)\n",
        "        hidden_size = self.model.config.hidden_size\n",
        "\n",
        "        self.project = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(head_dropout),\n",
        "            torch.nn.Linear(hidden_size, hidden_size),\n",
        "            torch.nn.Dropout(head_dropout),\n",
        "            torch.nn.Linear(hidden_size, classes) # projection\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        res = self.model.forward(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "        res = res[0]\n",
        "        res = res[:,0,:] # encoding for <s> token\n",
        "        res = self.project(res)\n",
        "        return res\n",
        "\n",
        "    def parameters_num(self):\n",
        "        return sum(p.numel() for p in self.parameters())"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "3IsUXgp2PeKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,\n",
        "          train_dataloader,\n",
        "          valid_dataloader,\n",
        "          steps,\n",
        "          optimizer,\n",
        "          accelerator,\n",
        "          blind_steps=None,\n",
        "          loss_fn=torch.nn.BCELoss(),\n",
        "          main_metric=('f1', f1_score),\n",
        "          additional_metrics=[],\n",
        "          filepath='model_best_RoBERTa.pt',\n",
        "          load_best=True,\n",
        "          scheduler=None,\n",
        "          losses_dict=None):\n",
        "\n",
        "    if blind_steps == None:\n",
        "        blind_steps = len(train_dataloader) // 4\n",
        "\n",
        "    def evaluate():  # the first score returned is the main\n",
        "        model.eval()\n",
        "\n",
        "        y_trues = []\n",
        "        y_hats = []\n",
        "\n",
        "        loss = 0\n",
        "        k = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in valid_dataloader:\n",
        "\n",
        "                (ids, mask), y_true = batch\n",
        "                ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "                y_true = accelerator.prepare(y_true)\n",
        "                hots = torch.nn.functional.one_hot(y_true, 2).to(dtype=torch.float)\n",
        "                y_hat = torch.softmax(model.forward(input_ids=ids, attention_mask=mask),dim=-1)\n",
        "\n",
        "                loss += float(loss_fn(y_hat, hots))\n",
        "                k += 1\n",
        "\n",
        "                for i in range(y_true.shape[0]):\n",
        "                    y_trues.append(int(y_true[i]))\n",
        "                    y_hats.append(1 if y_hat[i][0] < y_hat[i][1] else 0)\n",
        "\n",
        "        scores = [(main_metric[0], main_metric[1](y_trues, y_hats))]\n",
        "\n",
        "        for metric in additional_metrics:\n",
        "            scores.append((metric[0], metric[1](y_trues, y_hats)))\n",
        "\n",
        "        model.train()\n",
        "        return scores + [('valid_loss', loss/k)]\n",
        "\n",
        "\n",
        "    def render_scores(scores, step, best=None):\n",
        "        print('{:05d} steps'.format(step), end=' ')\n",
        "\n",
        "        for score in scores:\n",
        "            print(\"| {}: {:.3f}\".format(*score), end=' ')\n",
        "\n",
        "        if best != None:\n",
        "            print('| best_score: {:.3f}'.format(best))\n",
        "\n",
        "\n",
        "    # initial scores\n",
        "    scores = evaluate()\n",
        "    render_scores(scores, 0)\n",
        "    best_score = scores[0][1]\n",
        "    torch.save(accelerator.unwrap_model(model).state_dict(), filepath)\n",
        "\n",
        "    # logs\n",
        "    if losses_dict != None:\n",
        "        losses_dict['train_loss'] = []\n",
        "        losses_dict['valid_loss'] = []\n",
        "        losses_dict[main_metric[0]] = []\n",
        "\n",
        "    epoch_loss = 0\n",
        "    k = 0\n",
        "\n",
        "    train_iter = iter(train_dataloader)\n",
        "    model.train()\n",
        "\n",
        "    for step in tqdm(range(steps)):\n",
        "\n",
        "        # retrieving a batch\n",
        "        try:\n",
        "            batch = next(train_iter)\n",
        "        except:\n",
        "            train_iter = iter(train_dataloader)\n",
        "            batch = next(train_iter)\n",
        "\n",
        "        (ids, mask), y_true = batch\n",
        "        ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "        y_true = accelerator.prepare(y_true)\n",
        "\n",
        "        # prediction\n",
        "        y_hat = torch.softmax(model.forward(input_ids=ids, attention_mask=mask),dim=-1)\n",
        "        hots = torch.nn.functional.one_hot(y_true, 2).to(dtype=torch.float)\n",
        "        loss = loss_fn(y_hat, hots)\n",
        "\n",
        "        # backprop\n",
        "        optimizer.zero_grad()\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler != None:\n",
        "            scheduler.step()\n",
        "\n",
        "        epoch_loss += float(loss)\n",
        "        k += 1\n",
        "\n",
        "        # evaluation\n",
        "        if (step + 1) % blind_steps == 0:\n",
        "            scores = evaluate() + [('train_loss', epoch_loss/k)]\n",
        "\n",
        "            if losses_dict != None:\n",
        "                losses_dict['valid_loss'].append(float(scores[-2][1]))\n",
        "                losses_dict['train_loss'].append(float(scores[-1][1]))\n",
        "                losses_dict[main_metric[0]].append(float(scores[0][1]))\n",
        "\n",
        "            if scores[0][1] > best_score:\n",
        "                best_score = scores[0][1]\n",
        "                torch.save(accelerator.unwrap_model(model).state_dict(), filepath)\n",
        "\n",
        "            render_scores(scores, step + 1, best=best_score)\n",
        "            epoch_loss = 0\n",
        "            k = 0\n",
        "\n",
        "    if load_best:\n",
        "        state_dict = torch.load(filepath)\n",
        "\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            if \"module.\" not in k:\n",
        "                name = 'module.' + k\n",
        "                new_state_dict[name] = v\n",
        "\n",
        "        model.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "V1wF7VDNPeKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = accelerator.device\n",
        "model_checkpoint = \"roberta-large\"\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)\n",
        "model = RobertaModel.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Create an instance of your custom Dataset class\n",
        "dataset = MyDataset(filtered_df, 'final_text', tokenizer)\n",
        "train_dataset, valid_dataset = dataset.train_valid_split()\n",
        "\n",
        "dataset_test = MyDatasetTest(filtered_test, 'final_text', tokenizer)\n",
        "\n",
        "# Create a DataLoader\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = FinetuneClassifier(head_dropout=.1)\n",
        "model = nn.DataParallel(model)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-6, weight_decay=1.5e-3)\n",
        "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, total_iters=500)\n",
        "logs_dict = {}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-22T22:05:44.569876Z",
          "iopub.execute_input": "2023-05-22T22:05:44.570253Z",
          "iopub.status.idle": "2023-05-22T22:06:01.718868Z",
          "shell.execute_reply.started": "2023-05-22T22:05:44.570221Z",
          "shell.execute_reply": "2023-05-22T22:06:01.717712Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "trusted": true,
        "id": "Yqq3DxZlPeKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "  model,\n",
        "  train_dataloader,\n",
        "  valid_dataloader,\n",
        "  2000,\n",
        "  optimizer,\n",
        "  accelerator,\n",
        "  blind_steps=100,\n",
        "  additional_metrics=[('precision', precision_score), ('recall', recall_score),('accuracy', accuracy_score)],\n",
        "  losses_dict=logs_dict,\n",
        "  scheduler=scheduler\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-22T22:05:44.569876Z",
          "iopub.execute_input": "2023-05-22T22:05:44.570253Z",
          "iopub.status.idle": "2023-05-22T22:06:01.718868Z",
          "shell.execute_reply.started": "2023-05-22T22:05:44.570221Z",
          "shell.execute_reply": "2023-05-22T22:06:01.717712Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "trusted": true,
        "id": "FtPhQsW9PeKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XLNet Model"
      ],
      "metadata": {
        "id": "rv7DrWLrPeKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, dataframe, text_column, tokenizer, target='target', max_length = 256):\n",
        "        self.data = []\n",
        "\n",
        "        for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), ncols=70):\n",
        "            text = row[text_column]\n",
        "            tokenized = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors='pt')\n",
        "            self.data.append(((tokenized['input_ids'][0].to(device), tokenized['attention_mask'][0].to(device)), torch.tensor(row[target]).to(device)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def train_valid_split(self, train_fraction=.8, shuffle=True):\n",
        "        num_train_examples = int(len(self) * train_fraction)\n",
        "        train_dataset = copy.deepcopy(self)\n",
        "\n",
        "        if shuffle:\n",
        "            random.shuffle(train_dataset.data)\n",
        "\n",
        "        valid_dataset = copy.deepcopy(train_dataset)\n",
        "        train_dataset.data = train_dataset.data[:num_train_examples]\n",
        "        valid_dataset.data = valid_dataset.data[num_train_examples:]\n",
        "\n",
        "        return train_dataset, valid_dataset"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "pOL2dOzQPeKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDatasetTest(Dataset):\n",
        "    def __init__(self, dataframe, text_column, tokenizer, max_length = 256):\n",
        "        self.data = []\n",
        "\n",
        "        for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), ncols=70):\n",
        "            text = row[text_column]\n",
        "            tokenized = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors='pt')\n",
        "            self.data.append((torch.tensor(row['id']).to(device) ,(tokenized['input_ids'][0].to(device), tokenized['attention_mask'][0].to(device))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "xxB4vBKYPeKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FinetuneClassifier(nn.Module):\n",
        "    def __init__(self, model=model_checkpoint, classes=2, head_dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = AutoModel.from_pretrained(model)\n",
        "        hidden_size = self.model.config.hidden_size\n",
        "\n",
        "        self.project = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(head_dropout),\n",
        "            torch.nn.Linear(hidden_size, hidden_size),\n",
        "            torch.nn.Dropout(head_dropout),\n",
        "            torch.nn.Linear(hidden_size, classes) # projection\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        res = self.model.forward(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "        res = res[0]\n",
        "        res = res[:,0,:] # encoding for <s> token\n",
        "        res = self.project(res)\n",
        "        return res\n",
        "\n",
        "    def parameters_num(self):\n",
        "        return sum(p.numel() for p in self.parameters())"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "Z4goMEZCPeKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,\n",
        "          train_dataloader,\n",
        "          valid_dataloader,\n",
        "          steps,\n",
        "          optimizer,\n",
        "          accelerator,\n",
        "          blind_steps=None,\n",
        "          loss_fn=torch.nn.BCELoss(),\n",
        "          main_metric=('f1', f1_score),\n",
        "          additional_metrics=[],\n",
        "          filepath='model_best_XLNet.pt',\n",
        "          load_best=True,\n",
        "          scheduler=None,\n",
        "          losses_dict=None):\n",
        "\n",
        "    if blind_steps == None:\n",
        "        blind_steps = len(train_dataloader) // 4\n",
        "\n",
        "    def evaluate():  # the first score returned is the main\n",
        "        model.eval()\n",
        "\n",
        "        y_trues = []\n",
        "        y_hats = []\n",
        "\n",
        "        loss = 0\n",
        "        k = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in valid_dataloader:\n",
        "\n",
        "                (ids, mask), y_true = batch\n",
        "                ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "                y_true = accelerator.prepare(y_true)\n",
        "                hots = torch.nn.functional.one_hot(y_true, 2).to(dtype=torch.float)\n",
        "                y_hat = torch.softmax(model.forward(input_ids=ids, attention_mask=mask),dim=-1)\n",
        "\n",
        "                loss += float(loss_fn(y_hat, hots))\n",
        "                k += 1\n",
        "\n",
        "                for i in range(y_true.shape[0]):\n",
        "                    y_trues.append(int(y_true[i]))\n",
        "                    y_hats.append(1 if y_hat[i][0] < y_hat[i][1] else 0)\n",
        "\n",
        "        scores = [(main_metric[0], main_metric[1](y_trues, y_hats))]\n",
        "\n",
        "        for metric in additional_metrics:\n",
        "            scores.append((metric[0], metric[1](y_trues, y_hats)))\n",
        "\n",
        "        model.train()\n",
        "        return scores + [('valid_loss', loss/k)]\n",
        "\n",
        "\n",
        "    def render_scores(scores, step, best=None):\n",
        "        print('{:05d} steps'.format(step), end=' ')\n",
        "\n",
        "        for score in scores:\n",
        "            print(\"| {}: {:.3f}\".format(*score), end=' ')\n",
        "\n",
        "        if best != None:\n",
        "            print('| best_score: {:.3f}'.format(best))\n",
        "\n",
        "\n",
        "    # initial scores\n",
        "    scores = evaluate()\n",
        "    render_scores(scores, 0)\n",
        "    best_score = scores[0][1]\n",
        "    torch.save(accelerator.unwrap_model(model).state_dict(), filepath)\n",
        "\n",
        "    # logs\n",
        "    if losses_dict != None:\n",
        "        losses_dict['train_loss'] = []\n",
        "        losses_dict['valid_loss'] = []\n",
        "        losses_dict[main_metric[0]] = []\n",
        "\n",
        "    epoch_loss = 0\n",
        "    k = 0\n",
        "\n",
        "    train_iter = iter(train_dataloader)\n",
        "    model.train()\n",
        "\n",
        "    for step in tqdm(range(steps)):\n",
        "\n",
        "        # retrieving a batch\n",
        "        try:\n",
        "            batch = next(train_iter)\n",
        "        except:\n",
        "            train_iter = iter(train_dataloader)\n",
        "            batch = next(train_iter)\n",
        "\n",
        "        (ids, mask), y_true = batch\n",
        "        ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "        y_true = accelerator.prepare(y_true)\n",
        "\n",
        "        # prediction\n",
        "        y_hat = torch.softmax(model.forward(input_ids=ids, attention_mask=mask),dim=-1)\n",
        "        hots = torch.nn.functional.one_hot(y_true, 2).to(dtype=torch.float)\n",
        "        loss = loss_fn(y_hat, hots)\n",
        "\n",
        "        # backprop\n",
        "        optimizer.zero_grad()\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler != None:\n",
        "            scheduler.step()\n",
        "\n",
        "        epoch_loss += float(loss)\n",
        "        k += 1\n",
        "\n",
        "        # evaluation\n",
        "        if (step + 1) % blind_steps == 0:\n",
        "            scores = evaluate() + [('train_loss', epoch_loss/k)]\n",
        "\n",
        "            if losses_dict != None:\n",
        "                losses_dict['valid_loss'].append(float(scores[-2][1]))\n",
        "                losses_dict['train_loss'].append(float(scores[-1][1]))\n",
        "                losses_dict[main_metric[0]].append(float(scores[0][1]))\n",
        "\n",
        "            if scores[0][1] > best_score:\n",
        "                best_score = scores[0][1]\n",
        "                torch.save(accelerator.unwrap_model(model).state_dict(), filepath)\n",
        "\n",
        "            render_scores(scores, step + 1, best=best_score)\n",
        "            epoch_loss = 0\n",
        "            k = 0\n",
        "\n",
        "    if load_best:\n",
        "        state_dict = torch.load(filepath)\n",
        "\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            if \"module.\" not in k:\n",
        "                name = 'module.' + k\n",
        "                new_state_dict[name] = v\n",
        "\n",
        "        model.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "N542w8ErPeKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = accelerator.device\n",
        "model_checkpoint = \"xlnet-large-cased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Create an instance of your custom Dataset class\n",
        "dataset = MyDataset(filtered_df, 'final_text', tokenizer)\n",
        "train_dataset, valid_dataset = dataset.train_valid_split()\n",
        "\n",
        "dataset_test = MyDatasetTest(filtered_test, 'final_text', tokenizer)\n",
        "\n",
        "# Create a DataLoader\n",
        "batch_size = 12\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = FinetuneClassifier(head_dropout=.1)\n",
        "model = nn.DataParallel(model)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, total_iters=500)\n",
        "logs_dict = {}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-22T22:25:13.246409Z",
          "iopub.execute_input": "2023-05-22T22:25:13.246869Z",
          "iopub.status.idle": "2023-05-22T22:31:27.925354Z",
          "shell.execute_reply.started": "2023-05-22T22:25:13.246830Z",
          "shell.execute_reply": "2023-05-22T22:31:27.924352Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "trusted": true,
        "id": "jJgJiu4NPeKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "  model,\n",
        "  train_dataloader,\n",
        "  valid_dataloader,\n",
        "  2000,\n",
        "  optimizer,\n",
        "  accelerator,\n",
        "  blind_steps=100,\n",
        "  additional_metrics=[('precision', precision_score), ('recall', recall_score),('accuracy', accuracy_score)],\n",
        "  losses_dict=logs_dict,\n",
        "  scheduler=scheduler\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-22T22:25:13.246409Z",
          "iopub.execute_input": "2023-05-22T22:25:13.246869Z",
          "iopub.status.idle": "2023-05-22T22:31:27.925354Z",
          "shell.execute_reply.started": "2023-05-22T22:25:13.246830Z",
          "shell.execute_reply": "2023-05-22T22:31:27.924352Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "trusted": true,
        "id": "55mM6iHoPeKI",
        "outputId": "b6933fed-3945-46c7-fbd0-a25902f4dada",
        "colab": {
          "referenced_widgets": [
            "e86f4a32687c425e9858a8d2c8f91543",
            "748313644f974b34b880f78b02fd79c8",
            "7bbcbcd956bf4b929b39c87966139ddc",
            "3dd2d15d15cb4307adbae41aa66562e9"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/761 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e86f4a32687c425e9858a8d2c8f91543"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "748313644f974b34b880f78b02fd79c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bbcbcd956bf4b929b39c87966139ddc"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "100%|████████████████████████████| 7485/7485 [00:17<00:00, 418.90it/s]\n100%|████████████████████████████| 3263/3263 [00:03<00:00, 967.56it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/1.44G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dd2d15d15cb4307adbae41aa66562e9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at xlnet-large-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00000 steps | f1: 0.397 | precision: 0.437 | recall: 0.363 | accuracy: 0.524 | valid_loss: 0.872 ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [03:58<00:00,  2.38s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00100 steps | f1: 0.312 | precision: 0.608 | recall: 0.210 | accuracy: 0.602 | valid_loss: 0.651 | train_loss: 0.870 | best_score: 0.397\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ELECTRA Model"
      ],
      "metadata": {
        "id": "U6oqOS96PeKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, dataframe, text_column, tokenizer, target='target', max_length = 256):\n",
        "        self.data = []\n",
        "\n",
        "        for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), ncols=70):\n",
        "            text = row[text_column]\n",
        "            tokenized = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors='pt')\n",
        "            self.data.append(((tokenized['input_ids'][0].to(device), tokenized['attention_mask'][0].to(device)), torch.tensor(row[target]).to(device)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def train_valid_split(self, train_fraction=.8, shuffle=True):\n",
        "        num_train_examples = int(len(self) * train_fraction)\n",
        "        train_dataset = copy.deepcopy(self)\n",
        "\n",
        "        if shuffle:\n",
        "            random.shuffle(train_dataset.data)\n",
        "\n",
        "        valid_dataset = copy.deepcopy(train_dataset)\n",
        "        train_dataset.data = train_dataset.data[:num_train_examples]\n",
        "        valid_dataset.data = valid_dataset.data[num_train_examples:]\n",
        "\n",
        "        return train_dataset, valid_dataset"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "tf53ew1lPeKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDatasetTest(Dataset):\n",
        "    def __init__(self, dataframe, text_column, tokenizer, max_length = 256):\n",
        "        self.data = []\n",
        "\n",
        "        for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), ncols=70):\n",
        "            text = row[text_column]\n",
        "            tokenized = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors='pt')\n",
        "            self.data.append((torch.tensor(row['id']).to(device) ,(tokenized['input_ids'][0].to(device), tokenized['attention_mask'][0].to(device))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "KdhDILU7PeKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FinetuneClassifier(nn.Module):\n",
        "    def __init__(self, model=model_checkpoint, classes=2, head_dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = ElectraModel.from_pretrained(model)\n",
        "        hidden_size = self.model.config.hidden_size\n",
        "\n",
        "        self.project = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(head_dropout),\n",
        "            torch.nn.Linear(hidden_size, hidden_size),\n",
        "            torch.nn.Dropout(head_dropout),\n",
        "            torch.nn.Linear(hidden_size, classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        last_hidden_state = outputs[0]\n",
        "        cls_output = last_hidden_state[:, 0, :]\n",
        "        cls_output = self.project(cls_output)\n",
        "        return cls_output\n",
        "\n",
        "    def parameters_num(self):\n",
        "        return sum(p.numel() for p in self.parameters())"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "fnJhptW8PeKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,\n",
        "          train_dataloader,\n",
        "          valid_dataloader,\n",
        "          steps,\n",
        "          optimizer,\n",
        "          accelerator,\n",
        "          blind_steps=None,\n",
        "          loss_fn=torch.nn.BCELoss(),\n",
        "          main_metric=('f1', f1_score),\n",
        "          additional_metrics=[],\n",
        "          filepath='model_best_ELECTRA.pt',\n",
        "          load_best=True,\n",
        "          scheduler=None,\n",
        "          losses_dict=None):\n",
        "\n",
        "    if blind_steps == None:\n",
        "        blind_steps = len(train_dataloader) // 4\n",
        "\n",
        "    def evaluate():  # the first score returned is the main\n",
        "        model.eval()\n",
        "\n",
        "        y_trues = []\n",
        "        y_hats = []\n",
        "\n",
        "        loss = 0\n",
        "        k = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in valid_dataloader:\n",
        "\n",
        "                (ids, mask), y_true = batch\n",
        "                ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "                y_true = accelerator.prepare(y_true)\n",
        "                hots = torch.nn.functional.one_hot(y_true, 2).to(dtype=torch.float)\n",
        "                y_hat = torch.softmax(model.forward(input_ids=ids, attention_mask=mask),dim=-1)\n",
        "\n",
        "                loss += float(loss_fn(y_hat, hots))\n",
        "                k += 1\n",
        "\n",
        "                for i in range(y_true.shape[0]):\n",
        "                    y_trues.append(int(y_true[i]))\n",
        "                    y_hats.append(1 if y_hat[i][0] < y_hat[i][1] else 0)\n",
        "\n",
        "        scores = [(main_metric[0], main_metric[1](y_trues, y_hats))]\n",
        "\n",
        "        for metric in additional_metrics:\n",
        "            scores.append((metric[0], metric[1](y_trues, y_hats)))\n",
        "\n",
        "        model.train()\n",
        "        return scores + [('valid_loss', loss/k)]\n",
        "\n",
        "\n",
        "    def render_scores(scores, step, best=None):\n",
        "        print('{:05d} steps'.format(step), end=' ')\n",
        "\n",
        "        for score in scores:\n",
        "            print(\"| {}: {:.3f}\".format(*score), end=' ')\n",
        "\n",
        "        if best != None:\n",
        "            print('| best_score: {:.3f}'.format(best))\n",
        "\n",
        "\n",
        "    # initial scores\n",
        "    scores = evaluate()\n",
        "    render_scores(scores, 0)\n",
        "    best_score = scores[0][1]\n",
        "    torch.save(accelerator.unwrap_model(model).state_dict(), filepath)\n",
        "\n",
        "    # logs\n",
        "    if losses_dict != None:\n",
        "        losses_dict['train_loss'] = []\n",
        "        losses_dict['valid_loss'] = []\n",
        "        losses_dict[main_metric[0]] = []\n",
        "\n",
        "    epoch_loss = 0\n",
        "    k = 0\n",
        "\n",
        "    train_iter = iter(train_dataloader)\n",
        "    model.train()\n",
        "\n",
        "    for step in tqdm(range(steps)):\n",
        "\n",
        "        # retrieving a batch\n",
        "        try:\n",
        "            batch = next(train_iter)\n",
        "        except:\n",
        "            train_iter = iter(train_dataloader)\n",
        "            batch = next(train_iter)\n",
        "\n",
        "        (ids, mask), y_true = batch\n",
        "        ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "        y_true = accelerator.prepare(y_true)\n",
        "\n",
        "        # prediction\n",
        "        y_hat = torch.softmax(model.forward(input_ids=ids, attention_mask=mask),dim=-1)\n",
        "        hots = torch.nn.functional.one_hot(y_true, 2).to(dtype=torch.float)\n",
        "        loss = loss_fn(y_hat, hots)\n",
        "\n",
        "        # backprop\n",
        "        optimizer.zero_grad()\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler != None:\n",
        "            scheduler.step()\n",
        "\n",
        "        epoch_loss += float(loss)\n",
        "        k += 1\n",
        "\n",
        "        # evaluation\n",
        "        if (step + 1) % blind_steps == 0:\n",
        "            scores = evaluate() + [('train_loss', epoch_loss/k)]\n",
        "\n",
        "            if losses_dict != None:\n",
        "                losses_dict['valid_loss'].append(float(scores[-2][1]))\n",
        "                losses_dict['train_loss'].append(float(scores[-1][1]))\n",
        "                losses_dict[main_metric[0]].append(float(scores[0][1]))\n",
        "\n",
        "            if scores[0][1] > best_score:\n",
        "                best_score = scores[0][1]\n",
        "                torch.save(accelerator.unwrap_model(model).state_dict(), filepath)\n",
        "\n",
        "            render_scores(scores, step + 1, best=best_score)\n",
        "            epoch_loss = 0\n",
        "            k = 0\n",
        "\n",
        "    if load_best:\n",
        "        state_dict = torch.load(filepath)\n",
        "\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            if \"module.\" not in k:\n",
        "                name = 'module.' + k\n",
        "                new_state_dict[name] = v\n",
        "\n",
        "        model.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "CxuQHxDgPeKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = accelerator.device\n",
        "model_checkpoint = 'google/electra-base-discriminator'\n",
        "\n",
        "tokenizer = ElectraTokenizer.from_pretrained(model_checkpoint)\n",
        "model = ElectraForSequenceClassification.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Create an instance of your custom Dataset class\n",
        "dataset = MyDataset(filtered_df, 'final_text', tokenizer)\n",
        "train_dataset, valid_dataset = dataset.train_valid_split()\n",
        "\n",
        "dataset_test = MyDatasetTest(filtered_test, 'final_text', tokenizer)\n",
        "\n",
        "# Create a DataLoader\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model = FinetuneClassifier(head_dropout=.1)\n",
        "model = nn.DataParallel(model)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, total_iters=500)\n",
        "logs_dict = {}"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "0oEAn-iBPeKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "  model,\n",
        "  train_dataloader,\n",
        "  valid_dataloader,\n",
        "  2000,\n",
        "  optimizer,\n",
        "  accelerator,\n",
        "  blind_steps=100,\n",
        "  additional_metrics=[('precision', precision_score), ('recall', recall_score),('accuracy', accuracy_score)],\n",
        "  losses_dict=logs_dict,\n",
        "  scheduler=scheduler\n",
        ")"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "V15DY6YOPeKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting"
      ],
      "metadata": {
        "id": "867jlnQePeKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'BERT'"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "YyHJrvNIPeKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(f'/kaggle/working/model_best_{model_name}.pt')\n",
        "\n",
        "new_state_dict = OrderedDict()\n",
        "for k, v in state_dict.items():\n",
        "    if 'module.' not in k:\n",
        "        name = 'module.' + k\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "model.load_state_dict(new_state_dict)\n",
        "\n",
        "def evaluate(model, valid_dataloader, metrics=[('f1', f1_score),('precision', precision_score), ('recall', recall_score),('accuracy', accuracy_score)]):\n",
        "    model.eval()\n",
        "\n",
        "    y_trues = []\n",
        "    y_hats = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_dataloader:\n",
        "\n",
        "            (ids, mask), y_true = batch\n",
        "            y_hat = torch.softmax(model.forward(input_ids=ids, attention_mask=mask),dim=-1)\n",
        "\n",
        "            for i in range(y_true.shape[0]):\n",
        "                y_trues.append(int(y_true[i]))\n",
        "                y_hats.append(1 if y_hat[i][0] < y_hat[i][1] else 0)\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    for metric in metrics:\n",
        "        scores.append((metric[0], metric[1](y_trues, y_hats)))\n",
        "\n",
        "    return scores\n",
        "\n",
        "scores = evaluate(model, valid_dataloader)\n",
        "print(scores)\n",
        "\n",
        "predictions_df = pd.DataFrame()\n",
        "for i, (ids, mask) in tqdm(dataset_test):\n",
        "    ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "    pred = model(input_ids=ids[None], attention_mask=mask[None])[0]\n",
        "    y_hat = 1 if pred[0] < pred[1] else 0\n",
        "    r = [int(i), y_hat]\n",
        "    predictions_df = pd.concat([predictions_df, pd.DataFrame(np.array(r)[None,:], columns=['id', 'target'])])\n",
        "\n",
        "predictions_df.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "hV13ljHrPeKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa Model with K-Fold"
      ],
      "metadata": {
        "id": "lYmHm1XbPeKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, dataframe, text_column, tokenizer, target='target', max_length = 256):\n",
        "        self.data = []\n",
        "\n",
        "        for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), ncols=70):\n",
        "            text = row[text_column]\n",
        "            tokenized = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors='pt')\n",
        "            self.data.append(((tokenized['input_ids'][0].to(device), tokenized['attention_mask'][0].to(device)), torch.tensor(row[target]).to(device)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "1iztUrbyPeKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDatasetTest(Dataset):\n",
        "    def __init__(self, dataframe, text_column, tokenizer, max_length = 256):\n",
        "        self.data = []\n",
        "\n",
        "        for index, row in tqdm(dataframe.iterrows(), total=len(dataframe), ncols=70):\n",
        "            text = row[text_column]\n",
        "            tokenized = tokenizer(text, padding=\"max_length\", truncation=True, max_length=256, return_tensors='pt')\n",
        "            self.data.append((torch.tensor(row['id']).to(device) ,(tokenized['input_ids'][0].to(device), tokenized['attention_mask'][0].to(device))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "eVVXhPxoPeKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FinetuneClassifier(nn.Module):\n",
        "    def __init__(self, model=model_checkpoint, classes=2, head_dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = RobertaModel.from_pretrained(model)\n",
        "        hidden_size = self.model.config.hidden_size\n",
        "\n",
        "        self.project = torch.nn.Sequential(\n",
        "            torch.nn.Dropout(head_dropout),\n",
        "            torch.nn.Linear(hidden_size, hidden_size),\n",
        "            torch.nn.Dropout(head_dropout),\n",
        "            torch.nn.Linear(hidden_size, classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        res = self.model.forward(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
        "        res = res[0]\n",
        "        res = res[:,0,:] # encoding for <s> token\n",
        "        res = self.project(res)\n",
        "        return res\n",
        "\n",
        "    def parameters_num(self):\n",
        "        return sum(p.numel() for p in self.parameters())"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "Eh2iW-JfPeKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,\n",
        "          train_dataloader,\n",
        "          valid_dataloader,\n",
        "          steps,\n",
        "          optimizer,\n",
        "          accelerator,\n",
        "          blind_steps=None,\n",
        "          loss_fn=torch.nn.BCELoss(),\n",
        "          main_metric=('f1', f1_score),\n",
        "          additional_metrics=[],\n",
        "          filepath='model_best_RoBERTa.pt',\n",
        "          load_best=True,\n",
        "          scheduler=None,\n",
        "          losses_dict=None):\n",
        "\n",
        "    if blind_steps == None:\n",
        "        blind_steps = len(train_dataloader) // 4\n",
        "\n",
        "    def evaluate():  # the first score returned is the main\n",
        "        model.eval()\n",
        "\n",
        "        y_trues = []\n",
        "        y_hats = []\n",
        "\n",
        "        loss = 0\n",
        "        k = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in valid_dataloader:\n",
        "\n",
        "                (ids, mask), y_true = batch\n",
        "                ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "                y_true = accelerator.prepare(y_true)\n",
        "                hots = torch.nn.functional.one_hot(y_true, 2).to(dtype=torch.float)\n",
        "                y_hat = torch.softmax(model.forward(input_ids=ids, attention_mask=mask),dim=-1)\n",
        "\n",
        "                loss += float(loss_fn(y_hat, hots))\n",
        "                k += 1\n",
        "\n",
        "                for i in range(y_true.shape[0]):\n",
        "                    y_trues.append(int(y_true[i]))\n",
        "                    y_hats.append(1 if y_hat[i][0] < y_hat[i][1] else 0)\n",
        "\n",
        "        scores = [(main_metric[0], main_metric[1](y_trues, y_hats))]\n",
        "\n",
        "        for metric in additional_metrics:\n",
        "            scores.append((metric[0], metric[1](y_trues, y_hats)))\n",
        "\n",
        "        model.train()\n",
        "        return scores + [('valid_loss', loss/k)]\n",
        "\n",
        "\n",
        "    def render_scores(scores, step, best=None):\n",
        "        print('{:05d} steps'.format(step), end=' ')\n",
        "\n",
        "        for score in scores:\n",
        "            print(\"| {}: {:.3f}\".format(*score), end=' ')\n",
        "\n",
        "        if best != None:\n",
        "            print('| best_score: {:.3f}'.format(best))\n",
        "\n",
        "\n",
        "    # initial scores\n",
        "    scores = evaluate()\n",
        "    render_scores(scores, 0)\n",
        "    best_score = scores[0][1]\n",
        "    torch.save(accelerator.unwrap_model(model).state_dict(), filepath)\n",
        "\n",
        "    # logs\n",
        "    if losses_dict != None:\n",
        "        losses_dict['train_loss'] = []\n",
        "        losses_dict['valid_loss'] = []\n",
        "        losses_dict[main_metric[0]] = []\n",
        "\n",
        "    epoch_loss = 0\n",
        "    k = 0\n",
        "\n",
        "    train_iter = iter(train_dataloader)\n",
        "    model.train()\n",
        "\n",
        "    for step in tqdm(range(steps)):\n",
        "\n",
        "        # retrieving a batch\n",
        "        try:\n",
        "            batch = next(train_iter)\n",
        "        except:\n",
        "            train_iter = iter(train_dataloader)\n",
        "            batch = next(train_iter)\n",
        "\n",
        "        (ids, mask), y_true = batch\n",
        "        ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "        y_true = accelerator.prepare(y_true)\n",
        "\n",
        "        # prediction\n",
        "        y_hat = torch.softmax(model.forward(input_ids=ids, attention_mask=mask),dim=-1)\n",
        "        hots = torch.nn.functional.one_hot(y_true, 2).to(dtype=torch.float)\n",
        "        loss = loss_fn(y_hat, hots)\n",
        "\n",
        "        # backprop\n",
        "        optimizer.zero_grad()\n",
        "        accelerator.backward(loss)\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler != None:\n",
        "            scheduler.step()\n",
        "\n",
        "        epoch_loss += float(loss)\n",
        "        k += 1\n",
        "\n",
        "        # evaluation\n",
        "        if (step + 1) % blind_steps == 0:\n",
        "            scores = evaluate() + [('train_loss', epoch_loss/k)]\n",
        "\n",
        "            if losses_dict != None:\n",
        "                losses_dict['valid_loss'].append(float(scores[-2][1]))\n",
        "                losses_dict['train_loss'].append(float(scores[-1][1]))\n",
        "                losses_dict[main_metric[0]].append(float(scores[0][1]))\n",
        "\n",
        "            if scores[0][1] > best_score:\n",
        "                best_score = scores[0][1]\n",
        "                torch.save(accelerator.unwrap_model(model).state_dict(), filepath)\n",
        "\n",
        "            render_scores(scores, step + 1, best=best_score)\n",
        "            epoch_loss = 0\n",
        "            k = 0\n",
        "\n",
        "    if load_best:\n",
        "        state_dict = torch.load(filepath)\n",
        "\n",
        "        new_state_dict = OrderedDict()\n",
        "        for k, v in state_dict.items():\n",
        "            if \"module.\" not in k:\n",
        "                name = 'module.' + k\n",
        "                new_state_dict[name] = v\n",
        "\n",
        "        model.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "id": "qyWsbL_xPeKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = accelerator.device\n",
        "model_checkpoint = \"roberta-large\"\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_checkpoint)\n",
        "model = RobertaModel.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Define the batch size and the number of folds\n",
        "batch_size = 16\n",
        "n_folds = 5\n",
        "skf = StratifiedKFold(n_splits=n_folds)\n",
        "\n",
        "# Iterating over each fold\n",
        "for fold, (train_index, valid_index) in enumerate(skf.split(filtered_df, filtered_df['target'])):\n",
        "\n",
        "    print(f'FOLD {fold + 1}')\n",
        "\n",
        "    # Split the data into train and validation datasets for the current fold\n",
        "    train_dataset = MyDataset(filtered_df.iloc[train_index], 'final_text', tokenizer)\n",
        "    valid_dataset = MyDataset(filtered_df.iloc[valid_index], 'final_text', tokenizer)\n",
        "\n",
        "    # Create DataLoaders for the current fold\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize model for the current fold\n",
        "    model = FinetuneClassifier(head_dropout=.1)\n",
        "    model = nn.DataParallel(model)\n",
        "    model.to(device)\n",
        "\n",
        "    # Initialize optimizer for the current fold\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-6, weight_decay=1e-3)\n",
        "    scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, total_iters=500)\n",
        "    logs_dict = {}\n",
        "\n",
        "    # Train the model for the current fold\n",
        "    train(\n",
        "      model,\n",
        "      train_dataloader,\n",
        "      valid_dataloader,\n",
        "      1500,\n",
        "      optimizer,\n",
        "      accelerator,\n",
        "      blind_steps=100,\n",
        "      additional_metrics=[('precision', precision_score), ('recall', recall_score),('accuracy', accuracy_score)],\n",
        "      filepath=f'model_best_RoBERTa_fold_{fold}.pt',\n",
        "      losses_dict=logs_dict,\n",
        "      scheduler=scheduler\n",
        "    )\n",
        "\n",
        "dataset_test = MyDatasetTest(filtered_test, 'final_text', tokenizer)\n",
        "\n",
        "for fold in range(n_folds):\n",
        "    model_path = f'/kaggle/working/model_best_RoBERTa_fold_{fold}.pt'\n",
        "    state_dict = torch.load(model_path)\n",
        "\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        if 'module.' not in k:\n",
        "            name = 'module.' + k\n",
        "            new_state_dict[name] = v\n",
        "\n",
        "    model.load_state_dict(new_state_dict)\n",
        "\n",
        "    predictions_df = pd.DataFrame()\n",
        "    for i, (ids, mask) in tqdm(dataset_test):\n",
        "        ids, mask = accelerator.prepare(ids), accelerator.prepare(mask)\n",
        "        pred = model(input_ids=ids[None], attention_mask=mask[None])[0]\n",
        "        y_hat = 1 if pred[0] < pred[1] else 0\n",
        "        r = [int(i), y_hat]\n",
        "        predictions_df = pd.concat([predictions_df, pd.DataFrame(np.array(r)[None,:], columns=['id', 'target'])])\n",
        "\n",
        "    # Add the fold's predictions to the combined predictions DataFrame\n",
        "    predictions_df.columns = ['id', f'target_fold_{fold}']\n",
        "    if fold == 0:\n",
        "        combined_predictions = predictions_df\n",
        "    else:\n",
        "        combined_predictions = combined_predictions.merge(predictions_df, on='id')\n",
        "\n",
        "combined_predictions['target'] = combined_predictions.iloc[:, 1:].mean(axis=1).round().astype(int)\n",
        "combined_predictions[['id', 'target']].to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-03T22:06:36.266535Z",
          "iopub.execute_input": "2023-06-03T22:06:36.268672Z",
          "iopub.status.idle": "2023-06-04T02:54:41.101161Z",
          "shell.execute_reply.started": "2023-06-03T22:06:36.268643Z",
          "shell.execute_reply": "2023-06-04T02:54:41.100081Z"
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "collapsed": true,
        "trusted": true,
        "id": "7hZ6dYluPeKH",
        "outputId": "898e4ab9-43a9-4598-a9e6-1c39e4344927",
        "colab": {
          "referenced_widgets": [
            "9cc4ce31266545ea8fdfb4295b12d786",
            "fdee624ad91147079adb107d75e8c629",
            "61d5a5ade61e4050b885590d26017881",
            "15738783aff544fdb77d3473b5faa10b"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/nlp-getting-started/sample_submission.csv\n/kaggle/input/nlp-getting-started/train.csv\n/kaggle/input/nlp-getting-started/test.csv\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/tmp/ipykernel_31/3457697087.py:72: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  filtered_df['clean_text'] = filtered_df['text'].apply(clean_text)\n/tmp/ipykernel_31/3457697087.py:80: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  filtered_df['combined'] = filtered_df.apply(combine_columns, axis=1)\n/tmp/ipykernel_31/3457697087.py:81: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  filtered_df['final_text'] =  filtered_df['clean_text']+' '+ filtered_df['combined']\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cc4ce31266545ea8fdfb4295b12d786"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdee624ad91147079adb107d75e8c629"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61d5a5ade61e4050b885590d26017881"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15738783aff544fdb77d3473b5faa10b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "FOLD 1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|████████████████████████████| 5988/5988 [00:14<00:00, 417.96it/s]\n100%|████████████████████████████| 1497/1497 [00:01<00:00, 787.64it/s]\nSome weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00000 steps | f1: 0.598 | precision: 0.426 | recall: 1.000 | accuracy: 0.426 | valid_loss: 0.782 ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|▋         | 100/1500 [03:23<6:26:13, 16.55s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00100 steps | f1: 0.539 | precision: 0.914 | recall: 0.382 | accuracy: 0.721 | valid_loss: 0.593 | train_loss: 0.701 | best_score: 0.598\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|█▎        | 200/1500 [06:51<6:18:06, 17.45s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00200 steps | f1: 0.781 | precision: 0.882 | recall: 0.701 | accuracy: 0.832 | valid_loss: 0.408 | train_loss: 0.491 | best_score: 0.781\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|██        | 300/1500 [10:20<5:47:06, 17.36s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00300 steps | f1: 0.783 | precision: 0.851 | recall: 0.726 | accuracy: 0.829 | valid_loss: 0.385 | train_loss: 0.430 | best_score: 0.783\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 27%|██▋       | 400/1500 [13:47<5:19:17, 17.42s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00400 steps | f1: 0.804 | precision: 0.823 | recall: 0.785 | accuracy: 0.836 | valid_loss: 0.397 | train_loss: 0.443 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 33%|███▎      | 500/1500 [17:12<4:35:53, 16.55s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00500 steps | f1: 0.791 | precision: 0.887 | recall: 0.713 | accuracy: 0.839 | valid_loss: 0.386 | train_loss: 0.386 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 40%|████      | 600/1500 [20:37<4:07:32, 16.50s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00600 steps | f1: 0.794 | precision: 0.777 | recall: 0.810 | accuracy: 0.820 | valid_loss: 0.412 | train_loss: 0.391 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 47%|████▋     | 700/1500 [24:01<3:40:12, 16.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00700 steps | f1: 0.790 | precision: 0.794 | recall: 0.785 | accuracy: 0.822 | valid_loss: 0.430 | train_loss: 0.366 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 53%|█████▎    | 800/1500 [27:25<3:12:42, 16.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00800 steps | f1: 0.780 | precision: 0.901 | recall: 0.688 | accuracy: 0.835 | valid_loss: 0.380 | train_loss: 0.384 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 60%|██████    | 900/1500 [30:50<2:44:50, 16.48s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00900 steps | f1: 0.775 | precision: 0.900 | recall: 0.680 | accuracy: 0.832 | valid_loss: 0.401 | train_loss: 0.312 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 67%|██████▋   | 1000/1500 [34:15<2:17:56, 16.55s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01000 steps | f1: 0.788 | precision: 0.848 | recall: 0.735 | accuracy: 0.831 | valid_loss: 0.416 | train_loss: 0.305 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 73%|███████▎  | 1100/1500 [37:39<1:50:24, 16.56s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01100 steps | f1: 0.773 | precision: 0.888 | recall: 0.685 | accuracy: 0.829 | valid_loss: 0.399 | train_loss: 0.334 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 80%|████████  | 1200/1500 [41:04<1:22:55, 16.59s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01200 steps | f1: 0.785 | precision: 0.873 | recall: 0.713 | accuracy: 0.834 | valid_loss: 0.414 | train_loss: 0.271 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 87%|████████▋ | 1300/1500 [44:28<55:06, 16.53s/it]  ",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01300 steps | f1: 0.777 | precision: 0.804 | recall: 0.752 | accuracy: 0.816 | valid_loss: 0.475 | train_loss: 0.255 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 93%|█████████▎| 1400/1500 [47:52<27:32, 16.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01400 steps | f1: 0.794 | precision: 0.833 | recall: 0.759 | accuracy: 0.832 | valid_loss: 0.435 | train_loss: 0.285 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1500/1500 [51:16<00:00,  2.05s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01500 steps | f1: 0.794 | precision: 0.850 | recall: 0.745 | accuracy: 0.835 | valid_loss: 0.418 | train_loss: 0.298 | best_score: 0.804\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "FOLD 2\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|████████████████████████████| 5988/5988 [00:06<00:00, 867.99it/s]\n100%|████████████████████████████| 1497/1497 [00:01<00:00, 938.40it/s]\nSome weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00000 steps | f1: 0.000 | precision: 0.000 | recall: 0.000 | accuracy: 0.574 | valid_loss: 0.699 ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|▋         | 100/1500 [03:28<6:46:52, 17.44s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00100 steps | f1: 0.689 | precision: 0.682 | recall: 0.696 | accuracy: 0.732 | valid_loss: 0.550 | train_loss: 0.668 | best_score: 0.689\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|█▎        | 200/1500 [06:56<6:15:40, 17.34s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00200 steps | f1: 0.767 | precision: 0.790 | recall: 0.745 | accuracy: 0.807 | valid_loss: 0.464 | train_loss: 0.480 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|██        | 300/1500 [10:21<5:30:27, 16.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00300 steps | f1: 0.752 | precision: 0.820 | recall: 0.694 | accuracy: 0.805 | valid_loss: 0.479 | train_loss: 0.399 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 27%|██▋       | 400/1500 [13:45<5:02:54, 16.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00400 steps | f1: 0.748 | precision: 0.827 | recall: 0.683 | accuracy: 0.804 | valid_loss: 0.469 | train_loss: 0.380 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 33%|███▎      | 500/1500 [17:10<4:35:16, 16.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00500 steps | f1: 0.738 | precision: 0.922 | recall: 0.614 | accuracy: 0.814 | valid_loss: 0.459 | train_loss: 0.379 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 40%|████      | 600/1500 [20:35<4:08:00, 16.53s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00600 steps | f1: 0.754 | precision: 0.727 | recall: 0.782 | accuracy: 0.782 | valid_loss: 0.555 | train_loss: 0.348 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 47%|████▋     | 700/1500 [24:00<3:40:20, 16.53s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00700 steps | f1: 0.753 | precision: 0.766 | recall: 0.740 | accuracy: 0.793 | valid_loss: 0.536 | train_loss: 0.347 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 53%|█████▎    | 800/1500 [27:24<3:12:51, 16.53s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00800 steps | f1: 0.745 | precision: 0.754 | recall: 0.737 | accuracy: 0.786 | valid_loss: 0.552 | train_loss: 0.314 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 60%|██████    | 900/1500 [30:49<2:45:27, 16.55s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00900 steps | f1: 0.735 | precision: 0.756 | recall: 0.715 | accuracy: 0.780 | valid_loss: 0.591 | train_loss: 0.281 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 67%|██████▋   | 1000/1500 [34:14<2:17:44, 16.53s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01000 steps | f1: 0.754 | precision: 0.839 | recall: 0.685 | accuracy: 0.810 | valid_loss: 0.483 | train_loss: 0.309 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 73%|███████▎  | 1100/1500 [37:39<1:50:14, 16.54s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01100 steps | f1: 0.742 | precision: 0.746 | recall: 0.738 | accuracy: 0.782 | valid_loss: 0.555 | train_loss: 0.288 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 80%|████████  | 1200/1500 [41:03<1:23:16, 16.66s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01200 steps | f1: 0.740 | precision: 0.762 | recall: 0.719 | accuracy: 0.785 | valid_loss: 0.600 | train_loss: 0.259 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 87%|████████▋ | 1300/1500 [44:28<55:13, 16.57s/it]  ",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01300 steps | f1: 0.730 | precision: 0.782 | recall: 0.685 | accuracy: 0.784 | valid_loss: 0.637 | train_loss: 0.222 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 93%|█████████▎| 1400/1500 [47:52<27:36, 16.57s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01400 steps | f1: 0.718 | precision: 0.774 | recall: 0.669 | accuracy: 0.776 | valid_loss: 0.674 | train_loss: 0.237 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1500/1500 [51:16<00:00,  2.05s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01500 steps | f1: 0.719 | precision: 0.698 | recall: 0.741 | accuracy: 0.753 | valid_loss: 0.671 | train_loss: 0.249 | best_score: 0.767\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "FOLD 3\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|████████████████████████████| 5988/5988 [00:06<00:00, 925.69it/s]\n100%|████████████████████████████| 1497/1497 [00:01<00:00, 924.53it/s]\nSome weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00000 steps | f1: 0.275 | precision: 0.480 | recall: 0.193 | accuracy: 0.567 | valid_loss: 0.690 ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|▋         | 100/1500 [03:30<7:03:06, 18.13s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00100 steps | f1: 0.631 | precision: 0.754 | recall: 0.542 | accuracy: 0.729 | valid_loss: 0.544 | train_loss: 0.659 | best_score: 0.631\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|█▎        | 200/1500 [06:57<6:17:48, 17.44s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00200 steps | f1: 0.763 | precision: 0.816 | recall: 0.716 | accuracy: 0.810 | valid_loss: 0.459 | train_loss: 0.488 | best_score: 0.763\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|██        | 300/1500 [10:26<5:50:15, 17.51s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00300 steps | f1: 0.772 | precision: 0.832 | recall: 0.721 | accuracy: 0.819 | valid_loss: 0.451 | train_loss: 0.414 | best_score: 0.772\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 27%|██▋       | 400/1500 [13:56<5:34:22, 18.24s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00400 steps | f1: 0.776 | precision: 0.785 | recall: 0.766 | accuracy: 0.811 | valid_loss: 0.441 | train_loss: 0.380 | best_score: 0.776\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 33%|███▎      | 500/1500 [17:23<4:48:44, 17.32s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00500 steps | f1: 0.782 | precision: 0.848 | recall: 0.726 | accuracy: 0.828 | valid_loss: 0.425 | train_loss: 0.363 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 40%|████      | 600/1500 [20:48<4:07:47, 16.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00600 steps | f1: 0.776 | precision: 0.787 | recall: 0.765 | accuracy: 0.812 | valid_loss: 0.477 | train_loss: 0.357 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 47%|████▋     | 700/1500 [24:13<3:40:18, 16.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00700 steps | f1: 0.782 | precision: 0.841 | recall: 0.730 | accuracy: 0.826 | valid_loss: 0.424 | train_loss: 0.352 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 53%|█████▎    | 800/1500 [27:37<3:12:34, 16.51s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00800 steps | f1: 0.773 | precision: 0.759 | recall: 0.787 | accuracy: 0.803 | valid_loss: 0.495 | train_loss: 0.325 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 60%|██████    | 900/1500 [31:02<2:45:05, 16.51s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00900 steps | f1: 0.768 | precision: 0.789 | recall: 0.749 | accuracy: 0.808 | valid_loss: 0.509 | train_loss: 0.315 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 67%|██████▋   | 1000/1500 [34:27<2:17:44, 16.53s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01000 steps | f1: 0.759 | precision: 0.719 | recall: 0.803 | accuracy: 0.782 | valid_loss: 0.598 | train_loss: 0.296 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 73%|███████▎  | 1100/1500 [37:52<1:50:12, 16.53s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01100 steps | f1: 0.762 | precision: 0.708 | recall: 0.824 | accuracy: 0.780 | valid_loss: 0.554 | train_loss: 0.319 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 80%|████████  | 1200/1500 [41:16<1:22:35, 16.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01200 steps | f1: 0.749 | precision: 0.676 | recall: 0.839 | accuracy: 0.760 | valid_loss: 0.679 | train_loss: 0.261 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 87%|████████▋ | 1300/1500 [44:41<55:04, 16.52s/it]  ",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01300 steps | f1: 0.766 | precision: 0.748 | recall: 0.785 | accuracy: 0.796 | valid_loss: 0.610 | train_loss: 0.249 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 93%|█████████▎| 1400/1500 [48:06<27:48, 16.69s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01400 steps | f1: 0.762 | precision: 0.732 | recall: 0.795 | accuracy: 0.788 | valid_loss: 0.604 | train_loss: 0.242 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1500/1500 [51:30<00:00,  2.06s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01500 steps | f1: 0.736 | precision: 0.674 | recall: 0.812 | accuracy: 0.752 | valid_loss: 0.744 | train_loss: 0.248 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "FOLD 4\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|████████████████████████████| 5988/5988 [00:06<00:00, 935.23it/s]\n100%|████████████████████████████| 1497/1497 [00:01<00:00, 956.38it/s]\nSome weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00000 steps | f1: 0.598 | precision: 0.432 | recall: 0.972 | accuracy: 0.444 | valid_loss: 0.696 ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|▋         | 100/1500 [03:35<7:38:40, 19.66s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00100 steps | f1: 0.627 | precision: 0.856 | recall: 0.495 | accuracy: 0.749 | valid_loss: 0.606 | train_loss: 0.675 | best_score: 0.627\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|█▎        | 200/1500 [07:10<7:04:56, 19.61s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00200 steps | f1: 0.771 | precision: 0.720 | recall: 0.830 | accuracy: 0.790 | valid_loss: 0.487 | train_loss: 0.505 | best_score: 0.771\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|██        | 300/1500 [10:35<5:30:23, 16.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00300 steps | f1: 0.768 | precision: 0.796 | recall: 0.743 | accuracy: 0.810 | valid_loss: 0.459 | train_loss: 0.438 | best_score: 0.771\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 27%|██▋       | 400/1500 [14:09<5:59:10, 19.59s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00400 steps | f1: 0.772 | precision: 0.795 | recall: 0.750 | accuracy: 0.812 | valid_loss: 0.425 | train_loss: 0.404 | best_score: 0.772\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 33%|███▎      | 500/1500 [17:38<4:51:55, 17.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00500 steps | f1: 0.780 | precision: 0.795 | recall: 0.766 | accuracy: 0.816 | valid_loss: 0.414 | train_loss: 0.382 | best_score: 0.780\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 40%|████      | 600/1500 [21:03<4:07:05, 16.47s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00600 steps | f1: 0.779 | precision: 0.723 | recall: 0.846 | accuracy: 0.796 | valid_loss: 0.490 | train_loss: 0.380 | best_score: 0.780\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 47%|████▋     | 700/1500 [24:28<3:39:34, 16.47s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00700 steps | f1: 0.777 | precision: 0.800 | recall: 0.755 | accuracy: 0.816 | valid_loss: 0.421 | train_loss: 0.368 | best_score: 0.780\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 53%|█████▎    | 800/1500 [28:01<3:47:14, 19.48s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00800 steps | f1: 0.781 | precision: 0.769 | recall: 0.793 | accuracy: 0.810 | valid_loss: 0.445 | train_loss: 0.312 | best_score: 0.781\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 60%|██████    | 900/1500 [31:37<3:14:44, 19.47s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00900 steps | f1: 0.782 | precision: 0.761 | recall: 0.804 | accuracy: 0.809 | valid_loss: 0.439 | train_loss: 0.343 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 67%|██████▋   | 1000/1500 [35:02<2:17:32, 16.50s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01000 steps | f1: 0.766 | precision: 0.768 | recall: 0.765 | accuracy: 0.802 | valid_loss: 0.459 | train_loss: 0.335 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 73%|███████▎  | 1100/1500 [38:27<1:50:12, 16.53s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01100 steps | f1: 0.762 | precision: 0.891 | recall: 0.666 | accuracy: 0.823 | valid_loss: 0.454 | train_loss: 0.309 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 80%|████████  | 1200/1500 [41:51<1:22:40, 16.54s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01200 steps | f1: 0.758 | precision: 0.714 | recall: 0.807 | accuracy: 0.780 | valid_loss: 0.498 | train_loss: 0.303 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 87%|████████▋ | 1300/1500 [45:16<55:06, 16.53s/it]  ",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01300 steps | f1: 0.765 | precision: 0.768 | recall: 0.763 | accuracy: 0.801 | valid_loss: 0.487 | train_loss: 0.271 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 93%|█████████▎| 1400/1500 [48:41<27:33, 16.54s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01400 steps | f1: 0.757 | precision: 0.831 | recall: 0.695 | accuracy: 0.810 | valid_loss: 0.515 | train_loss: 0.252 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1500/1500 [52:06<00:00,  2.08s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01500 steps | f1: 0.760 | precision: 0.761 | recall: 0.760 | accuracy: 0.796 | valid_loss: 0.485 | train_loss: 0.274 | best_score: 0.782\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "FOLD 5\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|████████████████████████████| 5988/5988 [00:06<00:00, 903.82it/s]\n100%|████████████████████████████| 1497/1497 [00:01<00:00, 924.17it/s]\nSome weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00000 steps | f1: 0.597 | precision: 0.426 | recall: 1.000 | accuracy: 0.426 | valid_loss: 0.708 ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "  7%|▋         | 100/1500 [03:35<7:37:14, 19.60s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00100 steps | f1: 0.740 | precision: 0.843 | recall: 0.659 | accuracy: 0.803 | valid_loss: 0.515 | train_loss: 0.650 | best_score: 0.740\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 13%|█▎        | 200/1500 [07:10<7:02:49, 19.51s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00200 steps | f1: 0.812 | precision: 0.894 | recall: 0.744 | accuracy: 0.854 | valid_loss: 0.398 | train_loss: 0.483 | best_score: 0.812\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 20%|██        | 300/1500 [10:44<6:29:21, 19.47s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00300 steps | f1: 0.815 | precision: 0.770 | recall: 0.867 | accuracy: 0.833 | valid_loss: 0.435 | train_loss: 0.430 | best_score: 0.815\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 27%|██▋       | 400/1500 [14:12<5:22:39, 17.60s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00400 steps | f1: 0.822 | precision: 0.816 | recall: 0.829 | accuracy: 0.848 | valid_loss: 0.375 | train_loss: 0.424 | best_score: 0.822\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 33%|███▎      | 500/1500 [17:37<4:35:30, 16.53s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00500 steps | f1: 0.799 | precision: 0.890 | recall: 0.725 | accuracy: 0.845 | valid_loss: 0.371 | train_loss: 0.386 | best_score: 0.822\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 40%|████      | 600/1500 [21:02<4:08:07, 16.54s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00600 steps | f1: 0.798 | precision: 0.728 | recall: 0.882 | accuracy: 0.810 | valid_loss: 0.445 | train_loss: 0.378 | best_score: 0.822\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 47%|████▋     | 700/1500 [24:27<3:41:09, 16.59s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00700 steps | f1: 0.821 | precision: 0.854 | recall: 0.790 | accuracy: 0.853 | valid_loss: 0.363 | train_loss: 0.401 | best_score: 0.822\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 53%|█████▎    | 800/1500 [28:02<3:48:45, 19.61s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00800 steps | f1: 0.828 | precision: 0.852 | recall: 0.805 | accuracy: 0.858 | valid_loss: 0.357 | train_loss: 0.368 | best_score: 0.828\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 60%|██████    | 900/1500 [31:27<2:45:28, 16.55s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "00900 steps | f1: 0.821 | precision: 0.857 | recall: 0.788 | accuracy: 0.854 | valid_loss: 0.369 | train_loss: 0.332 | best_score: 0.828\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 67%|██████▋   | 1000/1500 [34:55<2:25:34, 17.47s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01000 steps | f1: 0.830 | precision: 0.860 | recall: 0.802 | accuracy: 0.860 | valid_loss: 0.370 | train_loss: 0.317 | best_score: 0.830\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 73%|███████▎  | 1100/1500 [38:20<1:49:39, 16.45s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01100 steps | f1: 0.817 | precision: 0.784 | recall: 0.854 | accuracy: 0.838 | valid_loss: 0.404 | train_loss: 0.360 | best_score: 0.830\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 80%|████████  | 1200/1500 [41:44<1:22:34, 16.52s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01200 steps | f1: 0.795 | precision: 0.715 | recall: 0.896 | accuracy: 0.804 | valid_loss: 0.563 | train_loss: 0.280 | best_score: 0.830\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 87%|████████▋ | 1300/1500 [45:09<55:02, 16.51s/it]  ",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01300 steps | f1: 0.817 | precision: 0.811 | recall: 0.823 | accuracy: 0.843 | valid_loss: 0.403 | train_loss: 0.311 | best_score: 0.830\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 93%|█████████▎| 1400/1500 [48:35<27:36, 16.56s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01400 steps | f1: 0.814 | precision: 0.821 | recall: 0.807 | accuracy: 0.843 | valid_loss: 0.406 | train_loss: 0.306 | best_score: 0.830\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1500/1500 [51:59<00:00,  2.08s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "01500 steps | f1: 0.805 | precision: 0.747 | recall: 0.873 | accuracy: 0.820 | valid_loss: 0.504 | train_loss: 0.294 | best_score: 0.830\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n100%|███████████████████████████| 3263/3263 [00:03<00:00, 1068.31it/s]\n100%|██████████| 3263/3263 [04:26<00:00, 12.23it/s]\n100%|██████████| 3263/3263 [04:27<00:00, 12.20it/s]\n100%|██████████| 3263/3263 [04:31<00:00, 12.01it/s]\n100%|██████████| 3263/3263 [04:31<00:00, 12.01it/s]\n100%|██████████| 3263/3263 [04:31<00:00, 12.03it/s]\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}
